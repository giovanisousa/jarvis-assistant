"""
Brain V2 com Sistema de Logging Integrado
Vers√£o com monitoramento completo de erros e eventos
"""

import json
import os
import time
import traceback
from google import genai
from google.genai import types
from config import Config
from datetime import datetime
from ferramentas import ApexFerramentas
from logger import get_logger

# Inicializa logger
log = get_logger("brain_v2")

class ApexBrain:
    def __init__(self):
        log.info("="*70)
        log.info("INICIALIZANDO APEX BRAIN V2")
        log.info("="*70)
        
        try:
            if not Config.GEMINI_KEY:
                log.critical("Chave do Gemini n√£o encontrada no .env!")
                raise ValueError("‚ùå Chave do Gemini n√£o encontrada no arquivo .env!")
            
            log.debug(f"API Key Gemini configurada: {Config.GEMINI_KEY[:15]}...")
            
            self.client = genai.Client(api_key=Config.GEMINI_KEY)
            self.model_name = "gemini-flash-latest"
            log.info(f"Modelo AI: {self.model_name}")
            
            self.arquivo_memoria = "db_memoria.json"
            self.cache_nota_pendente = None 
            
            # Carrega dados
            log.debug("Carregando dados do Zoho Projects...")
            self.dados_projetos = self.carregar_dados_zoho()
            log.info(f"‚úÖ Projetos carregados: {len(self.dados_projetos)}")
            
            log.debug("Carregando mem√≥ria local (anota√ß√µes)...")
            self.memoria_local = self.carregar_memoria_local()
            total_notas = sum(len(v) for v in self.memoria_local.values())
            log.info(f"‚úÖ Anota√ß√µes carregadas: {total_notas} em {len(self.memoria_local)} projetos")
            
            # Inicializa as "Ferramentas"
            log.debug("Inicializando m√≥dulo de ferramentas...")
            self.ferramentas = ApexFerramentas()
            log.info("‚úÖ Ferramentas (email, whatsapp, automa√ß√£o) prontas")
            
            # Hist√≥rico de Conversa (Mem√≥ria de Curto Prazo)
            self.historico_conversa = []
            self.max_historico = 10
            log.debug(f"Mem√≥ria conversacional configurada: {self.max_historico} intera√ß√µes")
            
            data_hoje = datetime.now().strftime("%d/%m/%Y √†s %H:%M")
            
            # Instru√ß√£o do sistema
            self.instrucao_sistema = self._construir_instrucao_sistema(data_hoje)
            log.debug(f"Sistema de instru√ß√£o constru√≠do: {len(self.instrucao_sistema)} caracteres")
            
            log.info(f"üéâ Brain V2 inicializado com sucesso em {data_hoje}")
            log.info("="*70)
            
        except Exception as e:
            log.critical("FALHA CR√çTICA na inicializa√ß√£o do Brain!", exception=e)
            raise

    def _construir_instrucao_sistema(self, data_hoje):
        """Constr√≥i a instru√ß√£o de sistema para a IA"""
        log.debug("Construindo prompt de instru√ß√£o do sistema...")
        
        return f"""Voc√™ √© APEX, o assistente executivo pessoal do Giovani na Animati.
Data/Hora atual: {data_hoje}

# PERSONALIDADE E TOM
- Seja DIRETO, CONCISO e NATURAL como em uma conversa real
- Use tom profissional mas amig√°vel (como no filme Homem de Ferro)
- Evite sauda√ß√µes longas ou formalidades excessivas
- NUNCA repita informa√ß√µes j√° ditas na conversa
- Se n√£o souber algo, admita honestamente

# FONTES DE DADOS
1. **Zoho Projects**: Dados t√©cnicos dos projetos (tarefas, %, prazos)
2. **Mem√≥ria do Gestor**: Anota√ß√µes contextuais que Giovani fez sobre os projetos
3. **Hist√≥rico da Conversa**: O que j√° foi discutido nesta sess√£o

# REGRAS DE NEG√ìCIO (ANIMATI)
- Fluxo: DEIP ‚Üí Infra ‚Üí Implanta√ß√£o (netRIS/PACS) ‚Üí Homologa√ß√£o ‚Üí Virada ‚Üí OA ‚Üí DPI
- Prazos: netRIS (35d), PACS (30d), OA (15d)
- FOQUE NO GARGALO: Fale apenas do que trava/atrasa, n√£o liste tudo que est√° ok
- Se projeto j√° est√° em fase avan√ßada (ex: Implanta√ß√£o), N√ÉO cite tarefas de fases anteriores (ex: Infra)

# DETEC√á√ÉO DE INTEN√á√ïES
Voc√™ deve identificar automaticamente a inten√ß√£o do usu√°rio e agir:

## INTEN√á√ïES DE CONSULTA (Responda em texto natural)
- Perguntas sobre status de projetos
- Pedidos de resumo/relat√≥rio
- An√°lises de situa√ß√£o
- Compara√ß√µes entre projetos

## INTEN√á√ïES DE A√á√ÉO (Execute via ferramentas)
Quando o usu√°rio pedir para FAZER algo, use JSON discretamente:

**EMAIL**: "envie email", "mande um email", "comunique por email"
‚Üí {{"ferramenta": "enviar_email", "params": {{"destinatario": "email", "assunto": "X", "corpo_html": "Y"}}}}

**BUSCAR EMAIL**: "veja meus emails", "tem algum email sobre X", "checa o email"
‚Üí {{"ferramenta": "buscar_emails", "params": {{"query": "termo", "apenas_nao_lidos": true/false}}}}

**WHATSAPP**: "manda mensagem pra X", "avisa a Patricia", "fala pro Jo√£o"
‚Üí {{"ferramenta": "enviar_whatsapp", "params": {{"contato": "Nome Exato", "mensagem": "texto"}}}}

**CLICAR NA TELA**: "clica no bot√£o X", "abre o programa Y"
‚Üí {{"ferramenta": "clicar_elemento_visual", "params": {{"descricao_elemento": "descri√ß√£o visual"}}}}

**DIGITAR**: "escreve X", "digita Y"
‚Üí {{"ferramenta": "digitar_texto", "params": {{"texto": "conte√∫do"}}}}

# IMPORTANTE
- Para a√ß√µes de WhatsApp, use o NOME EXATO mencionado pelo usu√°rio
- N√£o force JSON se o usu√°rio s√≥ quer conversar
- Adapte sua resposta ao contexto da conversa anterior
- Se for uma pergunta de acompanhamento, considere o hist√≥rico

# ANOTA√á√ïES NA MEM√ìRIA
Se o usu√°rio disser "anote que...", "lembre que...", "registre que...":
1. Identifique o projeto mencionado
2. Extraia o fato relevante
3. Confirme a anota√ß√£o de forma breve
"""

    def carregar_dados_zoho(self):
        """Carrega projetos do arquivo JSON"""
        try:
            caminho = "db_projetos.json"
            if not os.path.exists(caminho):
                log.warning(f"Arquivo {caminho} n√£o encontrado")
                return []
                
            with open(caminho, "r", encoding="utf-8") as f:
                dados = json.load(f)
                log.debug(f"Arquivo {caminho} lido com sucesso: {len(dados)} projetos")
                return dados
                
        except json.JSONDecodeError as e:
            log.error(f"Erro ao decodificar JSON de {caminho}", exception=e)
            return []
        except Exception as e:
            log.error(f"Erro inesperado ao carregar dados do Zoho", exception=e)
            return []

    def carregar_memoria_local(self):
        """Carrega anota√ß√µes do gestor"""
        try:
            if not os.path.exists(self.arquivo_memoria):
                log.debug(f"Arquivo de mem√≥ria n√£o existe, criando novo: {self.arquivo_memoria}")
                with open(self.arquivo_memoria, "w", encoding="utf-8") as f:
                    json.dump({}, f)
                return {}
                
            with open(self.arquivo_memoria, "r", encoding="utf-8") as f:
                dados = json.load(f)
                log.debug(f"Mem√≥ria carregada: {len(dados)} projetos com anota√ß√µes")
                return dados
                
        except json.JSONDecodeError as e:
            log.error("Erro ao decodificar mem√≥ria JSON", exception=e)
            return {}
        except Exception as e:
            log.error("Erro ao carregar mem√≥ria local", exception=e)
            return {}

    def adicionar_ao_historico(self, role, content):
        """Adiciona mensagem ao hist√≥rico de conversa"""
        try:
            self.historico_conversa.append({
                'role': role,
                'content': content,
                'timestamp': datetime.now().strftime("%H:%M:%S")
            })
            
            log.debug(f"Mensagem adicionada ao hist√≥rico: {role} - {content[:50]}...")
            
            # Limita tamanho
            if len(self.historico_conversa) > self.max_historico * 2:
                removidos = len(self.historico_conversa) - (self.max_historico * 2)
                self.historico_conversa = self.historico_conversa[-self.max_historico * 2:]
                log.debug(f"Hist√≥rico limitado: {removidos} mensagens antigas removidas")
                
        except Exception as e:
            log.error("Erro ao adicionar ao hist√≥rico", exception=e)

    def construir_contexto_conversa(self):
        """Monta o hist√≥rico formatado para a IA"""
        try:
            if not self.historico_conversa:
                log.debug("Hist√≥rico vazio, sem contexto conversacional")
                return ""
            
            contexto = "\n--- HIST√ìRICO DA CONVERSA ATUAL ---\n"
            ultimas_msg = self.historico_conversa[-6:]  # √öltimas 3 intera√ß√µes
            
            for msg in ultimas_msg:
                role_label = "GIOVANI" if msg["role"] == "user" else "APEX"
                contexto += f"[{msg['timestamp']}] {role_label}: {msg['content'][:200]}\n"
            
            contexto += "--- FIM DO HIST√ìRICO ---\n\n"
            log.debug(f"Contexto conversacional constru√≠do: {len(ultimas_msg)} mensagens")
            return contexto
            
        except Exception as e:
            log.error("Erro ao construir contexto conversacional", exception=e)
            return ""

    def salvar_memoria(self, projeto_id, nota):
        """Salva anota√ß√£o sobre um projeto"""
        try:
            projeto_id = str(projeto_id)
            log.info(f"Salvando anota√ß√£o no projeto {projeto_id}")
            log.debug(f"Nota: {nota}")
            
            if not os.path.exists(self.arquivo_memoria):
                with open(self.arquivo_memoria, "w", encoding="utf-8") as f:
                    json.dump({}, f)

            timestamp = datetime.now().strftime("%d/%m")
            nova_entrada = f"[{timestamp}] {nota}"
            
            if projeto_id not in self.memoria_local:
                self.memoria_local[projeto_id] = []
            
            self.memoria_local[projeto_id].append(nova_entrada)
            
            with open(self.arquivo_memoria, "w", encoding="utf-8") as f:
                json.dump(self.memoria_local, f, indent=4, ensure_ascii=False)
            
            log.info(f"‚úÖ Anota√ß√£o salva com sucesso no projeto {projeto_id}")
            return f"‚úÖ Anotado no projeto {projeto_id}."
            
        except Exception as e:
            log.error(f"Erro ao salvar mem√≥ria do projeto {projeto_id}", exception=e)
            return f"‚ùå Erro ao salvar anota√ß√£o: {str(e)}"

    def extrair_texto_nota(self, frase_usuario, nome_projeto_detectado):
        """Extrai o texto da nota usando IA"""
        try:
            log.debug(f"Extraindo nota de: {frase_usuario[:100]}")
            
            prompt_extracao = (
                f"Frase: '{frase_usuario}'. Contexto: '{nome_projeto_detectado}'. "
                "Extraia apenas o fato a ser anotado. Responda curto."
            )
            
            resp = self.client.models.generate_content(
                model=self.model_name, contents=prompt_extracao
            )
            
            nota = resp.text.strip()
            log.debug(f"Nota extra√≠da: {nota}")
            return nota
            
        except Exception as e:
            log.error("Erro ao extrair texto da nota", exception=e)
            return frase_usuario  # Fallback: usa a frase original

    def roteador_inteligente(self, pergunta):
        """Identifica projetos mencionados"""
        try:
            log.debug(f"Roteando pergunta: {pergunta[:100]}")
            pergunta_limpa = pergunta.lower()
            
            # Detecta modo de escrita
            gatilhos_escrita = ['anote', 'lembre', 'adicionar nota', 'gravar', 'registre']
            modo_escrita = any(g in pergunta_limpa for g in gatilhos_escrita)
            
            if modo_escrita:
                log.debug("Modo ESCRITA detectado")

            # Detecta consultas globais
            gatilhos_globais = ['quais', 'quantos', 'listar', 'relat√≥rio', 'resumo', 'todos', 'geral']
            
            if any(gatilho in pergunta_limpa for gatilho in gatilhos_globais) and not modo_escrita:
                log.info("Consulta GLOBAL detectada")
                return self.gerar_visao_helicoptero(self.dados_projetos), None, False

            # Busca por n√∫mero de projeto
            numeros = [p for p in pergunta_limpa.split() if p.isdigit()]
            log.debug(f"N√∫meros encontrados: {numeros}")
            
            for num in numeros:
                for proj in self.dados_projetos:
                    if num in proj.get("name", ""):
                        log.info(f"Projeto identificado por n√∫mero: {proj.get('name')}")
                        return [proj], None, modo_escrita

            # Busca por palavras-chave
            palavras_ignoradas = ['anote', 'que', 'sobre', 'projeto', 'no', 'na', 'o', 'a', 'para', 
                                  'fase', 'status', 'apex', 'situacao', 'situa√ß√£o', 'clique', 
                                  'mande', 'leia', 'email', 'whatsapp', 'mensagem']
            termos = [p for p in pergunta_limpa.split() if len(p) > 3 and p not in palavras_ignoradas]
            
            log.debug(f"Termos de busca: {termos}")
            
            projetos_encontrados = []
            if termos:
                for proj in self.dados_projetos:
                    if any(t in proj.get("name", "").lower() for t in termos):
                        projetos_encontrados.append(proj)

            if len(projetos_encontrados) == 1:
                log.info(f"Projeto √∫nico identificado: {projetos_encontrados[0].get('name')}")
                return projetos_encontrados, None, modo_escrita
            elif len(projetos_encontrados) > 1:
                log.warning(f"M√∫ltiplos projetos encontrados: {len(projetos_encontrados)}")
                nomes = "\n".join([f"- {p['name']}" for p in projetos_encontrados])
                return projetos_encontrados, f"Qual deles? (Diga o c√≥digo):\n{nomes}", modo_escrita
            
            if modo_escrita:
                log.warning("Modo escrita sem projeto identificado")
                return None, "Qual projeto? Diga o nome ou c√≥digo.", False
            
            log.debug("Nenhum projeto espec√≠fico identificado")
            return None, None, False
            
        except Exception as e:
            log.error("Erro no roteador inteligente", exception=e)
            return None, "Erro ao identificar projeto", False

    def gerar_visao_helicoptero(self, lista):
        """Gera vis√£o geral dos projetos"""
        try:
            log.debug(f"Gerando vis√£o geral de {len(lista)} projetos")
            dados = []
            
            for p in lista[:15]:
                notas = self.memoria_local.get(str(p['id']), [])
                fase = "Indefinida"
                
                for t in p.get("tasks", []):
                    status = str(t.get("status", "")).lower()
                    if status not in ["completed", "conclu√≠do", "cancelled", "fechado"]:
                        fase = t.get("tasklist", "Geral")
                        break
                
                dados.append({
                    "id": p['id'],
                    "name": p['name'],
                    "percent": p['percent_complete'],
                    "fase_real": fase,
                    "NOTAS": notas 
                })
            
            log.debug(f"Vis√£o geral gerada: {len(dados)} projetos processados")
            return dados
            
        except Exception as e:
            log.error("Erro ao gerar vis√£o helicoptero", exception=e)
            return []

    def analisar(self, pergunta):
        """M√©todo principal - COM LOGGING COMPLETO"""
        log.info("‚îÅ"*70)
        log.info("NOVA SOLICITA√á√ÉO RECEBIDA")
        log.info(f"Pergunta: {pergunta}")
        log.info("‚îÅ"*70)
        
        try:
            # Valida√ß√£o inicial
            if not self.dados_projetos and "email" not in pergunta.lower() and "whatsapp" not in pergunta.lower():
                log.warning("Sem dados de projetos e n√£o √© comando de a√ß√£o")
                return "Sem dados de projetos dispon√≠veis."

            print(f"\nüß† Processando: '{pergunta[:60]}...'")

            # Adiciona ao hist√≥rico
            self.adicionar_ao_historico("user", pergunta)

            # 1. L√≥gica de Mem√≥ria Pendente
            if self.cache_nota_pendente:
                log.debug(f"Processando nota pendente: {self.cache_nota_pendente}")
                numeros = [p for p in pergunta.split() if p.isdigit()]
                
                for num in numeros:
                    for proj in self.dados_projetos:
                        if num in proj.get("name", ""):
                            res = self.salvar_memoria(proj['id'], self.cache_nota_pendente)
                            self.cache_nota_pendente = None
                            self.adicionar_ao_historico("assistant", res)
                            log.info("Nota pendente salva")
                            return res
                
                self.cache_nota_pendente = None
                msg = "Opera√ß√£o cancelada. C√≥digo n√£o reconhecido."
                self.adicionar_ao_historico("assistant", msg)
                log.warning("C√≥digo n√£o reconhecido, nota cancelada")
                return msg

            # 2. Roteamento
            log.debug("Iniciando roteamento...")
            projetos_alvo, msg_erro, eh_escrita = self.roteador_inteligente(pergunta)
            
            if msg_erro:
                log.warning(f"Erro no roteamento: {msg_erro}")
                if eh_escrita and isinstance(projetos_alvo, list):
                    texto_nota = self.extrair_texto_nota(pergunta, "M√∫ltiplos")
                    self.cache_nota_pendente = texto_nota
                    self.adicionar_ao_historico("assistant", msg_erro)
                    return msg_erro 
                self.adicionar_ao_historico("assistant", msg_erro)
                return msg_erro

            if eh_escrita:
                log.info("Processando anota√ß√£o...")
                nota_limpa = self.extrair_texto_nota(pergunta, projetos_alvo[0]['name'])
                res = self.salvar_memoria(projetos_alvo[0]['id'], nota_limpa)
                self.adicionar_ao_historico("assistant", res)
                return res

            # 3. Prepara√ß√£o do Contexto
            log.debug("Construindo contexto...")
            contexto_conversa = self.construir_contexto_conversa()
            
            contexto_projetos = ""
            if projetos_alvo:
                dados_enriquecidos = []
                lista_para_contexto = projetos_alvo[:10] if isinstance(projetos_alvo, list) else projetos_alvo
                
                log.debug(f"Enriquecendo {len(lista_para_contexto) if isinstance(lista_para_contexto, list) else 1} projeto(s)")
                
                for p in lista_para_contexto:
                    p_completo = p.copy()
                    p_completo['MEMORIA_GESTOR'] = self.memoria_local.get(str(p.get('id')), [])
                    dados_enriquecidos.append(p_completo)

                contexto_projetos = f"\n--- DADOS DOS PROJETOS RELEVANTES ---\n{json.dumps(dados_enriquecidos, ensure_ascii=False)}\n"
                log.debug(f"Contexto de projetos: {len(contexto_projetos)} chars")
            
            # Monta prompt
            prompt = (
                f"{contexto_conversa}"
                f"{contexto_projetos}"
                f"\n--- SOLICITA√á√ÉO ATUAL ---\n{pergunta}\n\n"
                "INSTRU√á√ïES:\n"
                "- Se for uma pergunta sobre projetos: responda em texto natural, direto e conversacional\n"
                "- Se for um pedido de A√á√ÉO (email, whatsapp, clicar): responda APENAS com o JSON da ferramenta\n"
                "- Considere o hist√≥rico da conversa para dar contexto √†s suas respostas\n"
                "- N√ÉO repita informa√ß√µes j√° mencionadas anteriormente\n"
            )
            
            log.debug(f"Prompt constru√≠do: {len(prompt)} chars")
            log.debug("Chamando Gemini API...")
            
            resp = self.client.models.generate_content(
                model=self.model_name,
                contents=prompt,
                config=types.GenerateContentConfig(
                    system_instruction=self.instrucao_sistema, 
                    temperature=0.3
                )
            )
            
            log.info("‚úÖ Resposta recebida da API")
            resposta_texto = resp.text.strip()
            log.debug(f"Resposta (preview): {resposta_texto[:200]}...")

            # Adiciona ao hist√≥rico
            self.adicionar_ao_historico("assistant", resposta_texto[:500])

            # 4. Detecta a√ß√£o
            if "```json" in resposta_texto or (resposta_texto.startswith("{") and "ferramenta" in resposta_texto):
                log.info("Resposta identificada como A√á√ÉO (JSON)")
                return self.executar_ferramenta(resposta_texto)

            log.info("Resposta identificada como CONSULTA (texto)")
            log.info("‚úÖ Processamento conclu√≠do com sucesso")
            log.info("‚îÅ"*70)
            return resposta_texto
            
        except Exception as e:
            log.critical("‚ùå ERRO CR√çTICO no m√©todo analisar()", exception=e)
            log.error(f"Pergunta que causou erro: {pergunta}")
            log.error(f"Traceback completo:\n{traceback.format_exc()}")
            
            erro_user = f"‚ùå Erro ao processar: {type(e).__name__}. Verifique os logs em 'logs/erros.log'"
            self.adicionar_ao_historico("assistant", erro_user)
            return erro_user

    def executar_ferramenta(self, json_texto):
        """Executor das Ferramentas"""
        try:
            log.info("Executando ferramenta...")
            log.debug(f"JSON recebido: {json_texto[:200]}")
            
            json_limpo = json_texto.replace("```json", "").replace("```", "").strip()
            comando = json.loads(json_limpo)
            
            nome = comando.get("ferramenta")
            params = comando.get("params", {})
            
            log.info(f"Ferramenta: {nome}")
            log.debug(f"Par√¢metros: {params}")
            
            print(f"   ‚öôÔ∏è Ativando Ferramenta: {nome}...")
            log.registrar_acao(nome, str(params))

            resultado = None
            
            if nome == "buscar_emails":
                resultado = self.ferramentas.buscar_emails(**params)
            elif nome == "enviar_email":
                resultado = self.ferramentas.enviar_email(**params)
            elif nome == "clicar_elemento_visual":
                time.sleep(1)
                resultado = self.ferramentas.clicar_elemento_visual(params.get("descricao_elemento"))
            elif nome == "digitar_texto":
                resultado = self.ferramentas.digitar_texto(params.get("texto"))
            elif nome == "enviar_whatsapp":
                time.sleep(1)
                resultado = self.ferramentas.enviar_whatsapp(
                    params.get("contato"), 
                    params.get("mensagem")
                )
            else:
                resultado = f"‚ùå Ferramenta '{nome}' n√£o encontrada."
                log.error(f"Ferramenta n√£o encontrada: {nome}")
            
            log.info(f"‚úÖ Ferramenta executada: {resultado[:100]}")
            self.adicionar_ao_historico("assistant", f"[A√á√ÉO: {nome}] {resultado}")
            return resultado

        except json.JSONDecodeError as e:
            log.error("Erro ao decodificar JSON da ferramenta", exception=e)
            log.error(f"JSON problem√°tico: {json_texto}")
            return f"‚ùå Erro no formato JSON: {str(e)}"
        except Exception as e:
            log.error("Erro ao executar ferramenta", exception=e)
            return f"‚ùå Erro na execu√ß√£o: {str(e)}"

    def limpar_historico(self):
        """Limpa o hist√≥rico de conversa"""
        log.info("Limpando hist√≥rico de conversa")
        self.historico_conversa = []
        log.debug("Hist√≥rico limpo")
